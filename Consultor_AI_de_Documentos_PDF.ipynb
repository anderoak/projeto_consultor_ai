{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFieRvebp2tIBFmKOXjeXU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anderoak/projeto_consultor_ai/blob/main/Consultor_AI_de_Documentos_PDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Consultor AI de Documentos PDF\n",
        "Este notebook demonstra um projeto que combina a API Gemini com embeddings para criar um chatbot capaz de responder perguntas sobre o conteúdo de documentos e buscar informações relevantes em uma base de documentos PDF."
      ],
      "metadata": {
        "id": "xdTGQ-hggL-f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copyright © 2023 [Anderson Carvalho] - GNU GENERAL PUBLIC LICENSE"
      ],
      "metadata": {
        "id": "4mDRdroX0rL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Instruções para Utilização"
      ],
      "metadata": {
        "id": "5DnHT-AXieBN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  Adicione a sua chave de API do Google AI no Secrets, na barra lateral esquerda do Colab, definindo com o nome: GEMINI_API_KEY.\n",
        "-  Crie uma pasta chamada PDF no ambiente Colab. Você pode fazer clicando no ícone arquivos na lateral esquerda do Colab, depois clicando com o botão direito no espaço em branco e selecionando \"Nova pasta\".\n",
        "- Depois faça upload dos seus arquivos PDF e arraste-os para dentro da pasta PDF que criou. Leve em conta que a API do Gemini pode limitar de quantidade de dados carregados dos PDF se você está usando a versão gratuita da API, então use apenas um ou dois arquivos pequenos (deixei 2 arquivos que usei para testar no [repositório do GitHub](https://github.com/anderoak/projeto_consultor_ai), na pasta \"PDFs para teste\").\n",
        "- Garanta que os arquivos na pasta sejam realmente PDFs. Atente que esse projeto assume que os PDFs contêm texto extraível, portanto não irá funcionar com PDFs que são apenas imagens digitalizadas, pois exigiria técnicas de OCR (Optical Character Recognition) para extrair o texto.\n",
        "-  Execute o código célula por célula.\n",
        "-  Interaja com o chatbot fazendo perguntas sobre leis.\n",
        "-  Digite \"sair\" para encerrar o chat.\n",
        "\n",
        "Observação: Este é um exemplo básico genérico, mas que talvez possa se aprimorado adicionando mais funcionalidades, como especialização por área e uma interface web."
      ],
      "metadata": {
        "id": "rFa08CP3hQNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Instalação de Bibliotecas"
      ],
      "metadata": {
        "id": "LYz5FPpeiLcQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wjfR2v39gIp4"
      },
      "outputs": [],
      "source": [
        "# Instala as bibliotecas necessárias\n",
        "!pip install -q -U google-generativeai pypdf2\n",
        "\n",
        "# Importa as bibliotecas\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import numpy as np\n",
        "import PyPDF2\n",
        "\n",
        "# Lê a API Key do Secrets do Colab\n",
        "GOOGLE_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funções para processar PDFs"
      ],
      "metadata": {
        "id": "mK8oR23Aj4ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extrair_texto_pdf(caminho_arquivo):\n",
        "  \"\"\"\n",
        "  Extrai o texto de um arquivo PDF.\n",
        "  \"\"\"\n",
        "  with open(caminho_arquivo, 'rb') as arquivo_pdf:\n",
        "    leitor_pdf = PyPDF2.PdfReader(arquivo_pdf)\n",
        "    texto = \"\"\n",
        "    for num_pagina in range(len(leitor_pdf.pages)):\n",
        "      pagina = leitor_pdf.pages[num_pagina]\n",
        "      texto += pagina.extract_text()\n",
        "    return texto\n",
        "\n",
        "def carregar_documentos_pdf(pasta_colab='./PDF/'):\n",
        "  \"\"\"\n",
        "  Carrega os arquivos PDF de uma pasta no Colab e extrai o texto.\n",
        "  \"\"\"\n",
        "  import os\n",
        "  arquivos_pdf = [os.path.join(pasta_colab, arquivo)\n",
        "                   for arquivo in os.listdir(pasta_colab)\n",
        "                   if arquivo.endswith('.pdf')]\n",
        "\n",
        "  # Extrai o texto de cada arquivo PDF\n",
        "  documentos = [extrair_texto_pdf(arquivo) for arquivo in arquivos_pdf]\n",
        "  return documentos"
      ],
      "metadata": {
        "id": "NDLkdWUOjiW-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Configuração do Modelo Gemini"
      ],
      "metadata": {
        "id": "KJEi0ZpeghZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura os parâmetros do modelo Gemini\n",
        "generation_config = {\n",
        "    \"candidate_count\": 1,  # Número de respostas a serem geradas\n",
        "    \"temperature\": 0.5,   # Controla a criatividade das respostas\n",
        "}\n",
        "\n",
        "# Configura os parâmetros de segurança\n",
        "safety_settings = {\n",
        "    \"HARASSMENT\": \"BLOCK_NONE\",\n",
        "    \"HATE\": \"BLOCK_NONE\",\n",
        "    \"SEXUAL\": \"BLOCK_NONE\",\n",
        "    \"DANGEROUS\": \"BLOCK_NONE\",\n",
        "}\n",
        "\n",
        "# Inicializa o modelo Gemini\n",
        "model = genai.GenerativeModel(model_name='gemini-1.0-pro',\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)\n",
        "\n",
        "# Define o modelo de embedding\n",
        "embedding_model = \"models/embedding-001\""
      ],
      "metadata": {
        "id": "nCpf1WXzgkj7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Carregamento da Base de Dados e Embeddings"
      ],
      "metadata": {
        "id": "eHdRXrwPgnsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carrega os documentos da pasta do Colab\n",
        "documentos = carregar_documentos_pdf()\n",
        "\n",
        "# Gera embeddings para os documentos usando Gemini\n",
        "embeddings_documentos = []\n",
        "for documento in documentos:\n",
        "  embedding = genai.embed_content(model=embedding_model,\n",
        "                                  content=documento,\n",
        "                                  task_type=\"RETRIEVAL_DOCUMENT\")[\"embedding\"]\n",
        "  embeddings_documentos.append(embedding)"
      ],
      "metadata": {
        "id": "IoUKz8EUg1o7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Função de Busca por Similaridade"
      ],
      "metadata": {
        "id": "23uqv-b9g4AJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def buscar_documento(pergunta, embeddings_documentos, documentos):\n",
        "  \"\"\"\n",
        "  Busca o documento mais similar à pergunta usando embeddings.\n",
        "  \"\"\"\n",
        "  # Gera o embedding da pergunta usando Gemini\n",
        "  embedding_pergunta = genai.embed_content(model=embedding_model,\n",
        "                                           content=pergunta,\n",
        "                                           task_type=\"RETRIEVAL_QUERY\")[\"embedding\"]\n",
        "\n",
        "  # Calcula a similaridade cosseno entre a pergunta e os documentos\n",
        "  similaridades = np.dot(np.stack(embeddings_documentos), embedding_pergunta)\n",
        "\n",
        "  # Encontra o índice do documento mais similar\n",
        "  indice_documento_similar = np.argmax(similaridades)\n",
        "\n",
        "  # Retorna o documento mais similar\n",
        "  return documentos[indice_documento_similar]"
      ],
      "metadata": {
        "id": "T49-JIi_g9A7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Interação com o Chatbot"
      ],
      "metadata": {
        "id": "Wk20JIt1hAMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicia o chat\n",
        "chat = model.start_chat(history=[])\n",
        "\n",
        "# Loop de interação\n",
        "while True:\n",
        "  # Obtém a pergunta do usuário\n",
        "  pergunta = input(\"Pergunta: \")\n",
        "\n",
        "  # Busca o documento mais similar\n",
        "  documento_similar = buscar_documento(pergunta, embeddings_documentos, documentos)\n",
        "\n",
        "  # Envia a pergunta e o documento para o Gemini\n",
        "  resposta = chat.send_message(f\"Pergunta: {pergunta}\\nContexto: {documento_similar}\")\n",
        "\n",
        "  # Exibe a resposta do Gemini\n",
        "  print(f\"Resposta: {resposta.text}\")\n",
        "\n",
        "  # Condição de parada\n",
        "  if pergunta.lower() == 'sair':\n",
        "    break"
      ],
      "metadata": {
        "id": "cvJIActMhELS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}